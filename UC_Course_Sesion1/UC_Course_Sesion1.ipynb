{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0445209e-5bbf-4bb4-9033-adf71f9643ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. \uD83E\uDE99 Introducción a la Arquitectura Medallón\n",
    "\n",
    "La **arquitectura medallón** es un patrón de diseño ampliamente utilizado en entornos de **ingeniería de datos moderna**, especialmente en **Databricks** y **Delta Lake**.  \n",
    "Su objetivo es **estructurar los datos en capas sucesivas de calidad**, asegurando trazabilidad, gobernanza y rendimiento en los procesos analíticos.\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura clásica\n",
    "\n",
    "| Capa | Nombre | Propósito principal | Tipo de datos |\n",
    "|------|---------|--------------------|----------------|\n",
    "| \uD83E\uDD49 **Bronze** | *Raw / Landing* | Contiene los datos tal y como se reciben desde la fuente. Sin limpiar ni transformar. | Crudos, semi-estructurados o sin esquema definido |\n",
    "| \uD83E\uDD48 **Silver** | *Clean / Validated* | Aplica reglas de validación, limpieza, tipado y estandarización. Aquí se descartan o marcan los registros inválidos. | Limpios, consistentes, conformes con el modelo lógico |\n",
    "| \uD83E\uDD47 **Gold** | *Curated / Business-ready* | Contiene datos agregados o listos para análisis, reporting y dashboards. | Métricas y KPIs de negocio |\n",
    "\n",
    "Este enfoque en capas permite:\n",
    "- **Controlar la calidad** y trazabilidad de los datos.  \n",
    "- **Facilitar la depuración** de errores o inconsistencias.  \n",
    "- **Optimizar el rendimiento** mediante particiones y Z-ORDER.  \n",
    "- **Habilitar auditorías y lineage completo** desde origen hasta capa de consumo.  \n",
    "\n",
    "---\n",
    "\n",
    "# ⚙️ Extensión del modelo: Tabla de Cuarentena\n",
    "\n",
    "Durante la **validación en la capa Silver**, algunos registros no cumplen las reglas de calidad (por ejemplo, tipos erróneos, valores nulos críticos o claves no existentes).  \n",
    "En lugar de descartarlos definitivamente, se almacenan en una **tabla de cuarentena** —paralela a la Silver— que guarda **los registros rechazados** junto con información del error detectado.\n",
    "\n",
    "Esto permite:\n",
    "- **Preservar trazabilidad total**, sin pérdida de información.  \n",
    "- **Revisar y corregir manual o automáticamente** los registros problemáticos.  \n",
    "- **Retroalimentar la capa Silver** una vez corregidos.  \n",
    "\n",
    "---\n",
    "\n",
    "### Flujo extendido del modelo\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[Bronze \uD83E\uDD49 <br/> (Raw / Landing)] --> B[Silver \uD83E\uDD48 <br/> (Validated)]\n",
    "    B --> C[Gold \uD83E\uDD47 <br/> (Business-ready)]\n",
    "    B --> D[[Quarantine \uD83E\uDDF0 <br/> (Errores detectados)]]\n",
    "    D -->|Registros corregidos| B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc64ab05-960e-47ee-b41a-5548cf94c65f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. Descripcion de los Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "394128b0-ee79-475f-9f09-f6f61a11e1fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "## 1) `fleet_dim_aircraft.csv` (tabla de dimensión)\n",
    "Catálogo maestro de aeronaves.\n",
    "\n",
    "- **aircraft_id** *(STRING)*: Identificador interno único del avión (clave para joins).\n",
    "- **tail_number** *(STRING)*: Matrícula de la aeronave (p. ej., EC-XXX).\n",
    "- **model** *(STRING)*: Modelo (p. ej., A320-214, A321neo).\n",
    "- **manufacturer** *(STRING)*: Fabricante (p. ej., Airbus).\n",
    "- **engine_model** *(STRING)*: Modelo de motor (p. ej., CFM56-5B4).\n",
    "- **first_service_dt** *(DATE)*: Fecha de entrada en servicio.\n",
    "- **status** *(STRING)*: Estado operativo (Active | Maintenance | Retired).\n",
    "- **cycles_total** *(INT)*: Ciclos acumulados (despegue/aterrizaje).\n",
    "- **hours_total** *(DOUBLE)*: Horas de vuelo acumuladas.\n",
    "\n",
    "**Relación:** Se une con las tablas de hechos por `aircraft_id`.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) `ops_fact_engine_sensor.csv` (tabla de hechos – telemetría simplificada)\n",
    "Muestras de telemetría (baja resolución para demo) y **12 columnas**.\n",
    "\n",
    "- **reading_id** *(STRING)*: Identificador único de la lectura (UUID).\n",
    "- **aircraft_id** *(STRING)*: FK a `fleet_dim_aircraft.aircraft_id`.\n",
    "- **event_ts** *(TIMESTAMP, UTC en ISO8601)*: Marca temporal del evento.\n",
    "- **event_date** *(DATE)*: Fecha derivada de `event_ts` (útil para particionado).\n",
    "- **engine_pos** *(TINYINT)*: Posición del motor (1=izq., 2=dcha.).\n",
    "- **phase_of_flight** *(STRING)*: Fase del vuelo (Taxi/Takeoff/Climb/Cruise/Descent/Landing).\n",
    "- **altitude_ft** *(INT)*: Altitud estimada en pies.\n",
    "- **ias_kts** *(INT)*: Indicated Airspeed (nudos).\n",
    "- **egt_c** *(DOUBLE)*: Exhaust Gas Temperature (°C).\n",
    "- **n1_pct** *(DOUBLE)*: % de RPM del fan (N1).\n",
    "- **fuel_flow_kg_h** *(DOUBLE)*: Caudal de combustible (kg/h).\n",
    "- **vib_ips** *(DOUBLE)*: Vibración en pulgadas/segundo.\n",
    "\n",
    "**Uso típico:** generación de *features* de ventana por `aircraft_id` + `event_ts` (p. ej., medias móviles de `egt_c`, `vib_ips`, `n1_pct`).\n",
    "\n",
    "---\n",
    "\n",
    "## 3) `mro_fact_maintenance_event_50k.csv` (tabla de hechos – 50k filas)\n",
    "Histórico de eventos de mantenimiento, inspecciones y correctivos.\n",
    "\n",
    "- **event_id** *(STRING)*: Identificador del evento (UUID).\n",
    "- **aircraft_id** *(STRING)*: FK a `fleet_dim_aircraft.aircraft_id`.\n",
    "- **event_ts** *(TIMESTAMP, UTC en ISO8601)*: Fecha y hora del evento.\n",
    "- **event_date** *(DATE)*: Fecha derivada (útil para particionado).\n",
    "- **event_type** *(STRING)*: Tipo de evento (Inspection | A-Check | Unscheduled | Corrective | Replacement).\n",
    "- **ata_chapter** *(STRING)*: Capítulo ATA (sistema afectado, p. ej., “72 Engine”).\n",
    "- **defect_code** *(STRING)*: Código interno de defecto.\n",
    "- **severity** *(STRING)*: Severidad percibida (Low | Medium | High | Critical).\n",
    "- **grounded** *(BOOLEAN)*: Si el avión quedó en tierra (AOG) por el evento.\n",
    "- **workorder_id** *(STRING)*: Orden de trabajo en el sistema MRO/ERP.\n",
    "- **duration_min** *(INT)*: Duración de la intervención (minutos).\n",
    "- **description** *(STRING)*: Resumen libre del trabajo/defecto.\n",
    "- **next_due_cycles** *(INT, nullable)*: Ciclos restantes hasta el siguiente check (si aplica).\n",
    "- **next_due_hours** *(DOUBLE, nullable)*: Horas restantes hasta el siguiente check (si aplica).\n",
    "\n",
    "**Uso típico:** sirve como **etiqueta/target** para modelos supervisados (p. ej., probabilidad de evento “Unscheduled/Corrective” en ≤ X horas).\n",
    "\n",
    "---\n",
    "\n",
    "## Recomendaciones de modelado\n",
    "- **Particionado por fecha** en tablas de hechos → `event_date`.\n",
    "- **Z-Ordering** (Delta Lake) sobre (`aircraft_id`, `event_ts`) para acelerar consultas por avión/ventana temporal.\n",
    "- **Calidad de datos**: Validar rangos físicos (e.g., `egt_c`, `n1_pct`) y coherencia de fases de vuelo.\n",
    "- **Features**: estadísticas móviles (5/15/60 min), deltas vs. baseline del avión, *lags* y *rolling std* sobre `vib_ips` y `egt_c`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec5fcd77-b695-4c5c-b0dc-2cfc5ec1c5bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3.\uD83C\uDFAF Objetivo del notebook\n",
    "\n",
    "En este notebook vamos a **simular un flujo completo dentro de la arquitectura medallón**, centrado en las capas **Bronze → Silver → Quarantine**.  \n",
    "El propósito es entender cómo estructurar un **Job de Databricks** que combine **procesos de validación, almacenamiento de errores y posterior recuperación de datos corregidos**.\n",
    "\n",
    "---\n",
    "\n",
    "## \uD83E\uDDE9 Flujo general del Job\n",
    "\n",
    "1. **Ingesta (Bronze)**  \n",
    "   - Lectura de los datos originales desde una fuente cruda (por ejemplo, CSV o Parquet).  \n",
    "   - Registro del esquema y almacenamiento sin transformaciones en la capa Bronze.\n",
    "\n",
    "2. **Validación y aterrizaje (Silver)**  \n",
    "   - Aplicación de reglas de calidad (tipos, duplicados, integridad referencial, valores nulos críticos, etc.).  \n",
    "   - Inserción de los registros válidos en la tabla Silver.  \n",
    "   - Derivación de los registros no válidos a la tabla de cuarentena.\n",
    "\n",
    "3. **Cuarentena (Quarantine)**  \n",
    "   - Almacenamiento de los registros rechazados junto con metadatos de error.  \n",
    "   - Revisión y posible corrección manual o automatizada.\n",
    "\n",
    "4. **Recuperación posterior**  \n",
    "   - Reprocesamiento de los registros en cuarentena que fueron corregidos.  \n",
    "   - Reinserción controlada en la tabla Silver tras validaciones adicionales.  \n",
    "\n",
    "---\n",
    "\n",
    "## \uD83D\uDCCA Resultados esperados\n",
    "\n",
    "- Tabla **Silver** con los datos válidos y consistentes.  \n",
    "- Tabla **Quarantine** con los registros inicialmente rechazados.  \n",
    "- Métricas que permitan evaluar la calidad de los datos:\n",
    "  - Porcentaje de registros válidos vs en cuarentena.  \n",
    "  - Evolución del número de registros corregidos y reincidentes.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70d2d40e-d5d6-43e5-b752-b00090da385f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4. Creación de Repositorio en Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dba1b06-912a-40c9-b651-c7c6251b9019",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--drop catalog if exists sesion1_2 cascade;\n",
    "drop schema if exists sesion1_2.layer20_bronze cascade;\n",
    "drop schema if exists sesion1_2.layer30_silver cascade;\n",
    "drop schema if exists sesion1_2.layer30_silver_quarantine cascade;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb77d444-bb86-4954-8d74-66c0348add92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG IF NOT EXISTS sesion1_2;\n",
    "\n",
    "-- 01 · Landing / Raw\n",
    "CREATE SCHEMA IF NOT EXISTS sesion1_2.layer10_landing;\n",
    "CREATE VOLUME IF NOT EXISTS sesion1_2.layer10_landing.volume;\n",
    "\n",
    "-- 02 · Bronze\n",
    "CREATE SCHEMA IF NOT EXISTS sesion1_2.layer20_bronze;\n",
    "\n",
    "-- 03 · Silver\n",
    "CREATE SCHEMA IF NOT EXISTS sesion1_2.layer30_silver;\n",
    "CREATE SCHEMA IF NOT EXISTS sesion1_2.layer30_silver_quarantine;\n",
    "\n",
    "-- 04 · Gold\n",
    "CREATE SCHEMA IF NOT EXISTS sesion1_2.layer40_gold;\n",
    "\n",
    "-- 99 · Operaciones / Configuración\n",
    "CREATE SCHEMA IF NOT EXISTS sesion1_2.layer99_ops;\n",
    "CREATE VOLUME IF NOT EXISTS sesion1_2.layer99_ops.configs;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fc176bb-2067-4eb3-81e4-8a0fc0133766",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 5. Ejercico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0910eb7-9ec5-40ed-a7a1-92a9b7674a02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ahora continuaremos con la creacion del JOB utilizando los .py preparados para ello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "091e6b7b-3ee0-4d88-8c83-a0ab8805cefe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## \uD83D\uDEE0️ 5. CREACIÓN DEL PRIMER WORKFLOW (Ingesta → Validación → Cuarentena)\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83D\uDCC2 5.1 Ingesta — Preparación\n",
    "\n",
    "- Coloca los CSV en el volumen:\n",
    "`/Volumes/sesion1_2/layer10_landing/volume`\n",
    "\n",
    "- Abre el archivo `01_ingesta_datos.py` y analiza:\n",
    "\n",
    "> **❓ Preguntas**\n",
    "> - ¿Qué argumentos son obligatorios?  \n",
    "> - ¿El schema se impone o es flexible en esta fase? ¿Qué opinión te merece esta decisión?  \n",
    "> - ¿Qué adiciones implementarías tú en esta fase de ingesta?  \n",
    "\n",
    "---\n",
    "\n",
    "### \uD83D\uDE80 5.2 Crea el primer **JOB de INGESTA** (tabla `dim_aircraft`)\n",
    "\n",
    "**Parámetros recomendados:**\n",
    "\n",
    "[\"--input_file=/Volumes/sesion1_2/layer10_landing/volume/fleet_dim_aircraft_errors3.csv\", \"--output_table=sesion1_2.layer20_bronze.dim_aircraft\", \"--write_mode=overwrite\", \"--partition_by=\"]\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 5.3 Validación de Datos\n",
    "\n",
    "Abre el archivo `02_validacion_datos.py` y responde:\n",
    "\n",
    "> **❓ Preguntas**\n",
    "> - ¿Qué argumentos son obligatorios?  \n",
    "> - Validaciones actuales incluidas:  \n",
    ">   1. Nulos en Clave Primaria  \n",
    ">   2. Duplicados en Clave Primaria  \n",
    ">   3. Columnas numéricas fuera de rango  \n",
    ">   4. Columnas no numéricas vacías  \n",
    ">   5. Fecha bien formateada  \n",
    "> - **¿Se te ocurre alguna validación adicional?**  \n",
    "> - **¿Preferirías que en este punto fuera autoschema?**\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83E\uDDEA 5.4 Crea el **JOB de VALIDACIÓN** (tabla `dim_aircraft`)\n",
    "\n",
    "**Parámetros recomendados:**\n",
    "\n",
    "[\"--input_table=sesion1_2.layer20_bronze.dim_aircraft\", \"--output_table=sesion1_2.layer30_silver.dim_aircraft\", \"--config_path=/Volumes/sesion1_2/layer99_ops/configs/schemas_enriched.json\", \"--table_name=dim_aircraft\", \"--write_mode=overwrite\", \"--quarantine_table=sesion1_2.layer30_silver_quarantine.dim_aircraft_quarantine\"]\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83D\uDD01 5.5 Repite para las Tablas del Caso Real\n",
    "\n",
    "Aplica los **dos JOBs anteriores** también sobre:\n",
    "\n",
    "- `fact_engine_sensor`  \n",
    "- `fact_maintenance_event`  \n",
    "\n",
    "---\n",
    "\n",
    "### \uD83D\uDE91 5.6 Notebook de **Recuperación de Cuarentena**\n",
    "\n",
    "Abre el notebook `03_cuarentena_recov` y completa los ejercicios propuestos\n",
    "\n",
    "> **❓ Reflexión**\n",
    "> - ¿Qué opinas del uso de una tabla de cuarentena?  \n",
    "> - ¿Crearías un **KPI de % de datos eliminados vs % recuperados** tras cuarentena?  \n",
    "> - Completa las propuestas de lógica dentro del notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### \uD83D\uDD17 5.7 Agrega el Notebook al Workflow\n",
    "\n",
    "> **❓ Pregunta final**\n",
    "> - ¿Cómo ves el workflow resultante?  \n",
    "> - ¿Qué **siguiente dirección lógica** tomarías en un entorno real?\n",
    ">   - Reporting / Dashboard  \n",
    ">   - Automatizar alerts  \n",
    ">   - Curación manual asistida  \n",
    ">   - Limpieza iterativa Silver → Gold  \n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7960946099189801,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "UC_Course_Sesion1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}